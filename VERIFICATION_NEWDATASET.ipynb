{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "840f6401-eaf1-424f-bdd7-77b73cce599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df691124-3c14-4b94-b47a-cbe64a895703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "355c2a28-19fd-40a0-9f12-08bffbff7277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from JSON file\n",
    "file_path = 'C:/Users/HP/Desktop/angles_output_newww.json'\n",
    "data = []\n",
    "with open(file_path) as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ee09bcf-5149-4d46-9abc-96279d8cb1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert JSON data to DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "906bfd95-73da-46f7-8a81-80264692b034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = df.drop('Label', axis=1).values\n",
    "y = df['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8ab379c-bbf7-448a-b875-c46ad5b6bb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ee20b2-e1ec-415f-8319-7bfc5f60e1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "276a1ead-095c-4e2b-85d6-f9529b538823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for LSTM\n",
    "X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d6d6bec-a7fe-4b6e-ae8d-e46460e1c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Input(shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "lstm_model.add(LSTM(50, name='lstm_layer'))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(Dense(len(label_encoder.classes_), activation='softmax', name='output_layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79c837ff-c303-4627-beeb-0f28705067a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model initially\n",
    "lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7feed16-0f8b-47df-9375-374dd21a7181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with layers 0 to 0 frozen...\n",
      "Epoch 1/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2848 - loss: 1.6522 - val_accuracy: 0.3204 - val_loss: 1.5694\n",
      "Epoch 2/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3042 - loss: 1.5402 - val_accuracy: 0.4807 - val_loss: 1.4770\n",
      "Epoch 3/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3908 - loss: 1.4703 - val_accuracy: 0.5912 - val_loss: 1.4001\n",
      "Epoch 4/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4809 - loss: 1.3998 - val_accuracy: 0.6354 - val_loss: 1.3367\n",
      "Epoch 5/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5404 - loss: 1.3408 - val_accuracy: 0.6188 - val_loss: 1.2830\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6199 - loss: 1.2995 \n",
      "Validation Loss: 1.2830450534820557, Validation Accuracy: 0.6187845468521118\n",
      "Training with layers 0 to 1 frozen...\n",
      "Epoch 1/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5407 - loss: 1.2911 - val_accuracy: 0.6796 - val_loss: 1.2302\n",
      "Epoch 2/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5757 - loss: 1.2572 - val_accuracy: 0.6906 - val_loss: 1.1848\n",
      "Epoch 3/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6118 - loss: 1.2153 - val_accuracy: 0.7017 - val_loss: 1.1445\n",
      "Epoch 4/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6330 - loss: 1.1730 - val_accuracy: 0.7238 - val_loss: 1.1078\n",
      "Epoch 5/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6210 - loss: 1.1711 - val_accuracy: 0.7293 - val_loss: 1.0751\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7049 - loss: 1.0992\n",
      "Validation Loss: 1.0751192569732666, Validation Accuracy: 0.7292817831039429\n",
      "Training with layers 0 to 2 frozen...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:71: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6592 - loss: 1.1268 - val_accuracy: 0.7293 - val_loss: 1.0751\n",
      "Epoch 2/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6355 - loss: 1.1280 - val_accuracy: 0.7293 - val_loss: 1.0751\n",
      "Epoch 3/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6531 - loss: 1.1288 - val_accuracy: 0.7293 - val_loss: 1.0751\n",
      "Epoch 4/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6668 - loss: 1.1037 - val_accuracy: 0.7293 - val_loss: 1.0751\n",
      "Epoch 5/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6685 - loss: 1.1187 - val_accuracy: 0.7293 - val_loss: 1.0751\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7049 - loss: 1.0992\n",
      "Validation Loss: 1.0751192569732666, Validation Accuracy: 0.7292817831039429\n"
     ]
    }
   ],
   "source": [
    "# Iterative layer freezing\n",
    "for i in range(len(lstm_model.layers)):\n",
    "    # Freeze all layers up to the current layer\n",
    "    for j in range(i + 1):\n",
    "        lstm_model.layers[j].trainable = False\n",
    "\n",
    "    # Re-compile the model to apply changes\n",
    "    lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print(f\"Training with layers 0 to {i} frozen...\")\n",
    "\n",
    "    # Train model for a few epochs\n",
    "    lstm_model.fit(X_train_lstm, y_train, epochs=5, batch_size=32, validation_data=(X_test_lstm, y_test))\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_loss, val_accuracy = lstm_model.evaluate(X_test_lstm, y_test)\n",
    "    print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd3104e4-3ea6-4e74-8726-420a279d6292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After loop, unfreeze all layers for final fine-tuning\n",
    "for layer in lstm_model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84c25830-c9d7-410f-bf8d-a2556a419cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model again for fine-tuning\n",
    "lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ce2c310-d152-4180-a10c-aba266358048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7288 - loss: 0.9939 - val_accuracy: 0.8950 - val_loss: 0.7901\n",
      "Epoch 2/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8039 - loss: 0.8059 - val_accuracy: 0.8895 - val_loss: 0.6782\n",
      "Epoch 3/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8152 - loss: 0.7314 - val_accuracy: 0.8674 - val_loss: 0.6246\n",
      "Epoch 4/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8505 - loss: 0.6622 - val_accuracy: 0.9006 - val_loss: 0.5438\n",
      "Epoch 5/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8576 - loss: 0.5864 - val_accuracy: 0.9006 - val_loss: 0.4993\n",
      "Epoch 6/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8833 - loss: 0.5582 - val_accuracy: 0.9116 - val_loss: 0.4715\n",
      "Epoch 7/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8764 - loss: 0.5186 - val_accuracy: 0.9227 - val_loss: 0.4356\n",
      "Epoch 8/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8749 - loss: 0.4988 - val_accuracy: 0.9171 - val_loss: 0.4154\n",
      "Epoch 9/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8784 - loss: 0.4714 - val_accuracy: 0.9227 - val_loss: 0.3905\n",
      "Epoch 10/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8843 - loss: 0.4557 - val_accuracy: 0.9337 - val_loss: 0.3699\n"
     ]
    }
   ],
   "source": [
    "# Perform fine-tuning\n",
    "lstm_history = lstm_model.fit(X_train_lstm, y_train, epochs=10, batch_size=32, validation_data=(X_test_lstm, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e770849-bd11-4ff5-8158-181e73060d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training history\n",
    "with open('training_history_newdataset.json', 'w') as f:\n",
    "    json.dump(lstm_history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bacd3dec-11b6-45d5-b180-555807c574c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the final LSTM model\n",
    "lstm_model.save('verification_model_newdataset.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a637a0-dc20-4ad0-b285-a6693b7c54ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
